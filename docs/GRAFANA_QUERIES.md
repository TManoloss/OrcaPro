# ðŸ“Š Grafana - Queries e Dashboards

Guia completo de queries Ãºteis para monitoramento dos microsserviÃ§os.

## ðŸŽ¯ Prometheus Queries

### HTTP Metrics

#### Taxa de RequisiÃ§Ãµes por Segundo
```promql
# Por serviÃ§o
rate(http_requests_total[5m])

# Por serviÃ§o e endpoint
sum by(service, path) (rate(http_requests_total[5m]))

# Total geral
sum(rate(http_requests_total[5m]))
```

#### Taxa de Erros
```promql
# Percentual de erros 5xx
sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) * 100

# Erros por serviÃ§o
sum by(service) (rate(http_requests_total{status=~"5.."}[5m]))

# Erros 4xx vs 5xx
sum by(status) (rate(http_requests_total{status=~"[45].."}[5m]))
```

#### LatÃªncia (Percentis)
```promql
# P50 (mediana)
histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))

# P95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# P99
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))

# Por endpoint
histogram_quantile(0.95, sum by(path, le) (rate(http_request_duration_seconds_bucket[5m])))
```

#### RequisiÃ§Ãµes mais lentas
```promql
# Top 5 endpoints mais lentos (P95)
topk(5, histogram_quantile(0.95, sum by(path, le) (rate(http_request_duration_seconds_bucket[5m]))))
```

### Business Metrics

#### Auth Service
```promql
# Total de usuÃ¡rios registrados
user_registrations_total

# Taxa de registros por hora
increase(user_registrations_total[1h])

# Taxa de logins bem-sucedidos
rate(user_logins_total[5m])

# Taxa de tentativas de login falhas
rate(failed_login_attempts_total[5m])

# Ratio de falhas de login
rate(failed_login_attempts_total[5m]) / rate(user_logins_total[5m])

# SessÃµes ativas
active_sessions

# Tokens gerados por minuto
rate(jwt_tokens_generated_total[1m]) * 60

# Taxa de sucesso de validaÃ§Ã£o de tokens
rate(jwt_tokens_validated_total{result="success"}[5m]) / rate(jwt_tokens_validated_total[5m]) * 100
```

#### Transaction Service
```promql
# Total de transaÃ§Ãµes criadas
transactions_created_total

# TransaÃ§Ãµes criadas por tipo
sum by(type) (transactions_created_total)

# TransaÃ§Ãµes criadas por categoria
sum by(category) (transactions_created_total)

# Taxa de criaÃ§Ã£o de transaÃ§Ãµes
rate(transactions_created_total[5m])

# TransaÃ§Ãµes criadas na Ãºltima hora
increase(transactions_created_total[1h])

# TransaÃ§Ãµes atualizadas
transactions_updated_total

# TransaÃ§Ãµes deletadas
transactions_deleted_total

# DistribuiÃ§Ã£o de valores de transaÃ§Ãµes
histogram_quantile(0.95, rate(transaction_amount_bucket[5m]))
```

### RabbitMQ Metrics
```promql
# Mensagens publicadas com sucesso
rate(rabbitmq_messages_published_total{status="success"}[5m])

# Taxa de erros de publicaÃ§Ã£o
rate(rabbitmq_messages_published_total{status="error"}[5m])

# Percentual de sucesso
rate(rabbitmq_messages_published_total{status="success"}[5m]) / rate(rabbitmq_messages_published_total[5m]) * 100

# LatÃªncia de publicaÃ§Ã£o (P95)
histogram_quantile(0.95, rate(rabbitmq_message_publish_duration_seconds_bucket[5m]))

# Status da conexÃ£o (1=conectado, 0=desconectado)
rabbitmq_connection_status

# Mensagens por routing key
sum by(routing_key) (rate(rabbitmq_messages_published_total[5m]))
```

### Database Metrics
```promql
# ConexÃµes ativas
database_connections_active

# LatÃªncia de queries (P95)
histogram_quantile(0.95, rate(database_query_duration_seconds_bucket[5m]))

# Queries mais lentas por tipo
topk(5, histogram_quantile(0.95, sum by(query_type, le) (rate(database_query_duration_seconds_bucket[5m]))))
```

### Redis Metrics
```promql
# LatÃªncia de operaÃ§Ãµes no Redis (P95)
histogram_quantile(0.95, rate(redis_operation_duration_seconds_bucket[5m]))

# OperaÃ§Ãµes por segundo
rate(redis_operation_duration_seconds_count[5m])
```

## ðŸ“ˆ Dashboards Recomendados

### Dashboard 1: Overview Geral

**Linha 1: Golden Signals**
- Taxa de RequisiÃ§Ãµes (gauge)
- Taxa de Erros (gauge)
- LatÃªncia P95 (gauge)
- SaturaÃ§Ã£o - ConexÃµes DB (gauge)

**Linha 2: GrÃ¡ficos de Tempo**
- RequisiÃ§Ãµes/s por serviÃ§o (graph)
- Taxa de erros ao longo do tempo (graph)
- LatÃªncia P50/P95/P99 (graph)

**Linha 3: Business Metrics**
- UsuÃ¡rios registrados (stat)
- Logins/hora (stat)
- TransaÃ§Ãµes criadas/hora (stat)
- SessÃµes ativas (stat)

### Dashboard 2: Auth Service

```json
{
  "panels": [
    {
      "title": "Registros de UsuÃ¡rios",
      "targets": [{
        "expr": "user_registrations_total"
      }]
    },
    {
      "title": "Taxa de Logins (req/s)",
      "targets": [{
        "expr": "rate(user_logins_total[5m])"
      }]
    },
    {
      "title": "Tentativas de Login Falhas",
      "targets": [{
        "expr": "rate(failed_login_attempts_total[5m])"
      }]
    },
    {
      "title": "SessÃµes Ativas",
      "targets": [{
        "expr": "active_sessions"
      }]
    },
    {
      "title": "LatÃªncia de RequisiÃ§Ãµes",
      "targets": [
        {
          "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{service=\"auth-service\"}[5m]))",
          "legendFormat": "P50"
        },
        {
          "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{service=\"auth-service\"}[5m]))",
          "legendFormat": "P95"
        },
        {
          "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{service=\"auth-service\"}[5m]))",
          "legendFormat": "P99"
        }
      ]
    }
  ]
}
```

### Dashboard 3: Transaction Service

```promql
# Panel 1: TransaÃ§Ãµes Criadas por Tipo
sum by(type) (transactions_created_total)

# Panel 2: TransaÃ§Ãµes por Categoria (Top 10)
topk(10, sum by(category) (transactions_created_total))

# Panel 3: Taxa de CriaÃ§Ã£o de TransaÃ§Ãµes
rate(transactions_created_total[5m])

# Panel 4: DistribuiÃ§Ã£o de Valores
histogram_quantile(0.50, rate(transaction_amount_bucket[5m]))

# Panel 5: RabbitMQ - Mensagens Publicadas
rate(rabbitmq_messages_published_total{status="success"}[5m])

# Panel 6: LatÃªncia do RabbitMQ
histogram_quantile(0.95, rate(rabbitmq_message_publish_duration_seconds_bucket[5m]))
```

### Dashboard 4: RabbitMQ Deep Dive

```promql
# Panel 1: Taxa de PublicaÃ§Ã£o por Routing Key
sum by(routing_key) (rate(rabbitmq_messages_published_total[5m]))

# Panel 2: Taxa de Erros
rate(rabbitmq_messages_publish_errors_total[5m])

# Panel 3: Status da ConexÃ£o
rabbitmq_connection_status

# Panel 4: LatÃªncia de PublicaÃ§Ã£o (percentis)
histogram_quantile(0.50, rate(rabbitmq_message_publish_duration_seconds_bucket[5m]))
histogram_quantile(0.95, rate(rabbitmq_message_publish_duration_seconds_bucket[5m]))
histogram_quantile(0.99, rate(rabbitmq_message_publish_duration_seconds_bucket[5m]))
```

## ðŸ” Loki Queries (LogQL)

### Queries BÃ¡sicas

```logql
# Todos os logs de um serviÃ§o
{service="auth-service"}

# Logs de mÃºltiplos serviÃ§os
{service=~"auth-service|transaction-service"}

# Logs de erro
{} |= "error"

# Logs com level especÃ­fico (JSON)
{} | json | level="error"

# Logs de um usuÃ¡rio especÃ­fico
{} | json | user_id="abc-123"
```

### Queries AvanÃ§adas

```logql
# Logs de um trace_id especÃ­fico
{} | json | trace_id="4bf92f3577b34da6a3ce929d0e0e4736"

# Logs de criaÃ§Ã£o de transaÃ§Ãµes
{service="transaction-service"} |= "transaction created"

# Logs de autenticaÃ§Ã£o
{service="auth-service"} |= "logged in" or "login failed"

# Rate de erros nos Ãºltimos 5 minutos
rate({} | json | level="error" [5m])

# Count de erros agrupados por serviÃ§o
sum by(service) (count_over_time({} | json | level="error" [5m]))

# Logs com latÃªncia alta
{} | json | duration > 1s

# Logs de um endpoint especÃ­fico
{} | json | path="/api/v1/transactions"

# Pattern extraction
{service="auth-service"} | pattern "<_> user_id=<user_id> <_>"
```

### Queries para Debugging

```logql
# Erros de conexÃ£o com banco
{} |~ "(?i)database.*error|connection.*refused"

# Erros do RabbitMQ
{service="transaction-service"} |= "rabbitmq" |= "error"

# Requests lentas (> 1 segundo)
{} | json | latency > "1s"

# Failed login attempts
{service="auth-service"} |= "invalid password" or "user not found"

# Todos os eventos de uma requisiÃ§Ã£o (usando trace_id)
{} | json | trace_id="abc123" | line_format "{{.timestamp}} [{{.level}}] {{.service}} - {{.message}}"
```

### AgregaÃ§Ãµes e EstatÃ­sticas

```logql
# Contagem de logs por nÃ­vel
sum by(level) (count_over_time({} | json [5m]))

# Top 10 endpoints com mais erros
topk(10, sum by(path) (count_over_time({} | json | level="error" [1h])))

# LatÃªncia mÃ©dia por endpoint
avg_over_time({} | json | unwrap latency [5m]) by (path)

# Rate de logs por serviÃ§o
sum by(service) (rate({} [5m]))
```

## ðŸ“Š Alertas Importantes

### Alertas de SLA

```yaml
# Alert 1: Alta taxa de erros (> 5%)
groups:
  - name: sla_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m]))
            /
            sum(rate(http_requests_total[5m]))
          ) * 100 > 5
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Alta taxa de erros detectada"
          description: "{{ $value }}% das requisiÃ§Ãµes estÃ£o falhando"

      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 1
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "LatÃªncia P95 acima de 1 segundo"
          description: "P95 estÃ¡ em {{ $value }}s"

      - alert: ServiceDown
        expr: up{job=~"auth-service|transaction-service"} == 0
        for: 1m
        labels:
          severity: critical
          team: sre
        annotations:
          summary: "ServiÃ§o {{ $labels.job }} estÃ¡ down"
          description: "O serviÃ§o nÃ£o estÃ¡ respondendo"
```

### Alertas de NegÃ³cio

```yaml
      - alert: NoUserRegistrations
        expr: |
          increase(user_registrations_total[1h]) == 0
        for: 2h
        labels:
          severity: warning
          team: product
        annotations:
          summary: "Sem registros de usuÃ¡rios nas Ãºltimas 2 horas"
          description: "PossÃ­vel problema no fluxo de cadastro"

      - alert: HighLoginFailureRate
        expr: |
          (
            rate(failed_login_attempts_total[5m])
            /
            rate(user_logins_total[5m])
          ) > 0.5
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "Alta taxa de falhas de login"
          description: "{{ $value }}% dos logins estÃ£o falhando"

      - alert: RabbitMQPublishErrors
        expr: |
          rate(rabbitmq_messages_publish_errors_total[5m]) > 0
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Erros ao publicar mensagens no RabbitMQ"
          description: "Taxa de erros: {{ $value }}/s"
```

### Alertas de Infraestrutura

```yaml
      - alert: DatabaseConnectionsHigh
        expr: database_connections_active > 80
        for: 5m
        labels:
          severity: warning
          team: dba
        annotations:
          summary: "NÃºmero alto de conexÃµes no banco"
          description: "{{ $value }} conexÃµes ativas"

      - alert: RedisDown
        expr: redis_operation_duration_seconds_count == 0
        for: 2m
        labels:
          severity: critical
          team: sre
        annotations:
          summary: "Redis nÃ£o estÃ¡ respondendo"
          description: "Sem operaÃ§Ãµes no Redis nos Ãºltimos 2 minutos"

      - alert: RabbitMQDisconnected
        expr: rabbitmq_connection_status == 0
        for: 1m
        labels:
          severity: critical
          team: sre
        annotations:
          summary: "ConexÃ£o com RabbitMQ perdida"
          description: "ServiÃ§o {{ $labels.service }} desconectado do RabbitMQ"
```

## ðŸŽ¨ Templates de PainÃ©is Grafana

### Painel: Taxa de RequisiÃ§Ãµes com Threshold

```json
{
  "type": "graph",
  "title": "Request Rate",
  "targets": [
    {
      "expr": "sum(rate(http_requests_total[5m]))",
      "legendFormat": "Total Requests/s"
    }
  ],
  "thresholds": [
    {
      "value": 100,
      "colorMode": "custom",
      "fill": true,
      "line": true,
      "op": "gt",
      "fillColor": "rgba(255, 0, 0, 0.1)",
      "lineColor": "rgb(255, 0, 0)"
    }
  ]
}
```

### Painel: Heatmap de LatÃªncia

```json
{
  "type": "heatmap",
  "title": "Request Latency Distribution",
  "targets": [
    {
      "expr": "sum(rate(http_request_duration_seconds_bucket[5m])) by (le)",
      "format": "heatmap",
      "legendFormat": "{{le}}"
    }
  ]
}
```

### Painel: Status dos ServiÃ§os (Stat)

```json
{
  "type": "stat",
  "title": "Services Status",
  "targets": [
    {
      "expr": "up{job=~\"auth-service|transaction-service\"}",
      "legendFormat": "{{job}}"
    }
  ],
  "options": {
    "reduceOptions": {
      "values": false,
      "calcs": ["lastNotNull"]
    },
    "colorMode": "background",
    "graphMode": "none"
  },
  "fieldConfig": {
    "defaults": {
      "mappings": [
        {
          "type": "value",
          "options": {
            "0": { "text": "DOWN", "color": "red" },
            "1": { "text": "UP", "color": "green" }
          }
        }
      ]
    }
  }
}
```

## ðŸ”— Correlacionando Dados

### Logs â†’ Traces â†’ Metrics

**1. ComeÃ§ar com um erro nos logs:**
```logql
{service="transaction-service"} | json | level="error" | trace_id!=""
```

**2. Pegar o trace_id e buscar no Jaeger:**
```
http://localhost:16686/trace/{trace_id}
```

**3. Ver mÃ©tricas do perÃ­odo:**
```promql
rate(http_requests_total{status="500"}[5m])
```

### Exemplo de Workflow de InvestigaÃ§Ã£o

**CenÃ¡rio: API lenta**

1. **Verificar latÃªncia no Prometheus:**
```promql
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{path="/api/v1/transactions"}[5m]))
```

2. **Ver logs do perÃ­odo no Loki:**
```logql
{service="transaction-service", path="/api/v1/transactions"} 
| json 
| duration > 1s
```

3. **Pegar trace_id de uma request lenta e investigar no Jaeger**

4. **Verificar se hÃ¡ problema no banco:**
```promql
histogram_quantile(0.95, rate(database_query_duration_seconds_bucket[5m]))
```

5. **Verificar RabbitMQ:**
```promql
rate(rabbitmq_messages_publish_errors_total[5m])
```

## ðŸ“± VariÃ¡veis de Dashboard

### VariÃ¡vel: Service
```
Query: label_values(http_requests_total, service)
```

### VariÃ¡vel: Endpoint
```
Query: label_values(http_requests_total{service="$service"}, path)
```

### VariÃ¡vel: Time Range
```
Custom: 5m, 15m, 1h, 6h, 24h, 7d
```

### Uso em Queries
```promql
rate(http_requests_total{service="$service", path="$endpoint"}[$__rate_interval])
```

## ðŸŽ¯ Cheat Sheet RÃ¡pido

### Top Queries mais Ãšteis

```promql
# 1. Taxa de requisiÃ§Ãµes
sum(rate(http_requests_total[5m])) by (service)

# 2. Taxa de erros
sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)

# 3. LatÃªncia P95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# 4. TransaÃ§Ãµes por tipo
sum by(type) (transactions_created_total)

# 5. Status do RabbitMQ
rabbitmq_connection_status
```

### Top Loki Queries

```logql
# 1. Erros recentes
{} | json | level="error" | line_format "{{.timestamp}} {{.service}} - {{.message}}"

# 2. Logs de um trace
{} | json | trace_id="abc123"

# 3. Rate de erros
rate({} | json | level="error" [5m])

# 4. Top serviÃ§os com erros
topk(5, sum by(service) (count_over_time({} | json | level="error" [1h])))

# 5. Requests lentas
{} | json | duration > 1s
```

---

**ðŸ’¡ Dica**: Salve seus dashboards favoritos como JSON para versionamento no Git!